import streamlit as st
import os

# RAG Setup iÃ§in gerekli kÃ¼tÃ¼phaneler (rag_setup.py'den taÅŸÄ±ndÄ±)
import kagglehub
from langchain_google_genai import GoogleGenerativeAIEmbeddings
from langchain_community.vectorstores import Chroma
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_core.prompts import PromptTemplate
from langchain_core.runnables import RunnableLambda, RunnablePassthrough

# Unidecode kÃ¼tÃ¼phanesi (TÃ¼rkÃ§e karakter dÃ¼zeltmesi iÃ§in gerekli olabilir)
import unidecode 

# ----------------------------------------------------
# A. SABÄ°T DEÄÄ°ÅKENLER VE GÄ°ZLÄ° ANAHTARLAR
# ----------------------------------------------------
DB_PATH = "./chroma_db_translation"
MODEL_NAME = "gemini-2.5-flash"

# Streamlit Secrets'tan anahtarlarÄ± al
GEMINI_API_KEY = os.getenv("GEMINI_API_KEY")

if not GEMINI_API_KEY:
    # KullanÄ±cÄ±yÄ± Streamlit Secrets'a yÃ¶nlendir
    st.error("âŒ GEMINI_API_KEY bulunamadÄ±. LÃ¼tfen Streamlit Secrets'Ä± kontrol edin.")
    st.stop()

# ----------------------------------------------------
# B. RAG KURULUM FONKSÄ°YONU (SADECE BÄ°R KEZ Ã‡ALIÅIR)
# ----------------------------------------------------

def setup_rag_database():
    """
    Kaggle'dan veriyi indirir, iÅŸler ve ChromaDB veritabanÄ±nÄ± oluÅŸturur.
    Bu fonksiyon, veritabanÄ± klasÃ¶rÃ¼ mevcut deÄŸilse Ã§alÄ±ÅŸÄ±r.
    """
    if os.path.exists(DB_PATH):
        # VeritabanÄ± zaten var, kurulumu atla
        return

    st.warning("âš ï¸ VektÃ¶r veritabanÄ± bulunamadÄ±. Kurulum baÅŸlatÄ±lÄ±yor... LÃ¼tfen bekleyiniz.")
    
    # 2ï¸âƒ£ Kaggle dataset indir (rag_setup.py'den taÅŸÄ±ndÄ±)
    try:
        st.info("ğŸ“¦ Kaggle dataset indiriliyor... (Kaggle Secrets Kontrol Ediliyor)")
        # Kaggle, ortam deÄŸiÅŸkenlerini (KAGGLE_USERNAME, KAGGLE_KEY) otomatik kullanÄ±r
        dataset_path = kagglehub.dataset_download("seymasa/turkish-to-english-translation-dataset")
        st.success(f"âœ… Dataset baÅŸarÄ±yla indirildi: {dataset_path}")
    except Exception as e:
        st.error("âŒ Kaggle indirme hatasÄ±. LÃ¼tfen Streamlit Secrets'da KAGGLE_USERNAME ve KAGGLE_KEY'in doÄŸru olduÄŸundan emin olun.")
        st.code(str(e))
        st.stop()

    # 3ï¸âƒ£ TR2EN.txt dosyasÄ±nÄ± oku
    st.info("ğŸ“„ TR2EN.txt dosyasÄ± okunuyor ve iÅŸleniyor...")
    texts = []
    file_path = os.path.join(dataset_path, "TR2EN.txt")

    if not os.path.exists(file_path):
        st.error(f"âŒ TR2EN.txt dosyasÄ± {dataset_path} iÃ§inde bulunamadÄ±.")
        st.stop()

    with open(file_path, "r", encoding="utf-8") as f:
        for line in f:
            parts = line.strip().split("\t")
            if len(parts) == 2:
                eng, tur = parts
                # Metni RAG iÃ§in en uygun formata dÃ¶nÃ¼ÅŸtÃ¼r
                texts.append(f"Source (EN): {eng}\nTarget (TR): {tur}")

    st.caption(f"Toplam {len(texts)} Ã§eviri satÄ±rÄ± iÅŸlendi. Ä°lk 5 Ã¶rnek: {texts[:5]}")
    
    # âš™ï¸ Test iÃ§in sadece ilk 1000 satÄ±rÄ± kullan
    if len(texts) > 1000:
        texts = texts[:1000]

    # 4ï¸âƒ£ Metinleri parÃ§alara ayÄ±r
    st.info("ğŸ§© Veri parÃ§acÄ±klarÄ± oluÅŸturuluyor...")
    splitter = RecursiveCharacterTextSplitter(chunk_size=800, chunk_overlap=150)
    documents = splitter.create_documents(texts)
    st.caption(f"{len(documents)} metin parÃ§asÄ± oluÅŸturuldu.")

    # 5ï¸âƒ£ Embedding + Chroma veritabanÄ±
    st.info("ğŸ’¡ VektÃ¶r veritabanÄ± oluÅŸturuluyor... (Bu kÄ±sÄ±m biraz zaman alabilir)")
    embeddings = GoogleGenerativeAIEmbeddings(
        model="models/text-embedding-004",
        client_options={"api_key": GEMINI_API_KEY}
    )

    vectorstore = Chroma.from_documents(
        documents=documents,
        embedding=embeddings,
        persist_directory=DB_PATH
    )

    st.success("ğŸ‰ VektÃ¶r veritabanÄ± baÅŸarÄ±yla kaydedildi!")
    st.balloons()
    
    # Kurulum sonrasÄ± uygulamayÄ± yeniden yÃ¼kle
    st.rerun()

# ----------------------------------------------------
# C. CHATBOT UYGULAMA LOGÄ°ÄÄ°
# ----------------------------------------------------

@st.cache_resource
def get_llm():
    """Gemini modelini cache'ler."""
    return ChatGoogleGenerativeAI(
        model=MODEL_NAME, 
        temperature=0.0, 
        client_options={"api_key": GEMINI_API_KEY}
    )

@st.cache_resource
def get_vectorstore():
    """VektÃ¶r maÄŸazasÄ±nÄ± yÃ¼kler ve cache'ler."""
    try:
        embeddings = GoogleGenerativeAIEmbeddings(
            model="models/text-embedding-004",
            client_options={"api_key": GEMINI_API_KEY}
        )
        return Chroma(
            persist_directory=DB_PATH, 
            embedding_function=embeddings
        )
    except Exception as e:
        # EÄŸer DB yoksa veya yÃ¼klenemiyorsa hata dÃ¶ndÃ¼rÃ¼r
        return None

def translate_query(query, llm):
    """
    TÃ¼rkÃ§e sorgularÄ± Ä°ngilizceye Ã§evirir (Pre-Retrieval Translation).
    """
    # Sorgunun hangi dilde olduÄŸunu tespit et (Basit Kontrol)
    if any(char in query for char in "Ã§ÄŸÄ±Ã¶ÅŸÃ¼Ã‡ÄÄ°Ã–ÅÃœ"):
        # TÃ¼rkÃ§e ise Ä°ngilizceye Ã§evir
        prompt = f"Translate the following Turkish sentence to English only, strictly without any explanation or extra text: '{query}'"
        result = llm.invoke(prompt)
        return result.content
    else:
        # Zaten Ä°ngilizce kabul et veya Ã§eviriye gerek yok.
        return query

def format_docs(docs):
    """
    RAG baÄŸlamÄ± iÃ§in belgeleri biÃ§imlendirir.
    """
    return "\n\n".join(doc.page_content for doc in docs)

# ----------------------------------------------------
# D. ANA STREAMLIT AKIÅI
# ----------------------------------------------------

def main():
    st.set_page_config(page_title="RAG Ã‡eviri Chatbotu (Gemini)", layout="centered")
    st.title("ğŸ—£ï¸ RAG Destekli TÃ¼rkÃ§e â†” Ä°ngilizce Ã‡eviri")

    # 1. VeritabanÄ± KontrolÃ¼ ve Kurulumu
    if not os.path.exists(DB_PATH):
        # EÄŸer veritabanÄ± yoksa kurulumu baÅŸlat
        setup_rag_database()
        return # Kurulumu baÅŸlattÄ±ktan sonra ana akÄ±ÅŸÄ± durdur

    # 2. VektÃ¶r MaÄŸazasÄ±nÄ± YÃ¼kle
    vectorstore = get_vectorstore()
    if vectorstore is None:
        st.error("VeritabanÄ± yÃ¼klenemedi. LÃ¼tfen klasÃ¶rÃ¼n (chroma_db_translation) varlÄ±ÄŸÄ±nÄ± kontrol edin.")
        return

    llm = get_llm()
    retriever = vectorstore.as_retriever()
    
    # 3. Prompt ve Zincir TanÄ±mlama
    template = """
    Sen bir TÃ¼rkÃ§e/Ä°ngilizce Ã§eviri uzmanÄ±sÄ±n. GÃ¶revin, verilen SORGUsunu HEDEF DÄ°L'e Ã§evirmektir.
    Ã‡eviri yaparken, BaÄŸlam (Context) bÃ¶lÃ¼mÃ¼ndeki ilgili Ã§eviri Ã¶rneklerini (Source/Target Ã§iftleri) kullan.
    
    Hedef Dil: SORGUnun dili TÃ¼rkÃ§e ise Hedef Dil Ä°ngilizce'dir. SORGUnun dili Ä°ngilizce ise Hedef Dil TÃ¼rkÃ§e'dir.
    
    Kurallar:
    1. Sadece Ã§eviriyi dÃ¶ndÃ¼r. AÃ§Ä±klama, uyarÄ± veya ek not EKLEME.
    2. BaÄŸlamdaki kelime ve cÃ¼mle yapÄ±larÄ±nÄ± Ã§evirine dahil etmeye Ã§alÄ±ÅŸ.

    BaÄŸlam (Context):
    {context}

    Sorgu: {query}
    """
    rag_prompt = PromptTemplate.from_template(template)

    # 4. RAG Zinciri
    rag_chain = (
        RunnablePassthrough.assign(
            # 1. Sorguyu Ä°ngilizceye Ã§evir (RAG arama iÃ§in)
            retrieval_query=RunnableLambda(lambda x: translate_query(x['query'], llm)),
        )
        # 2. VektÃ¶r DB'de arama yap (Ä°ngilizce sorgu ile)
        | RunnablePassthrough.assign(
            context=RunnableLambda(lambda x: x['retrieval_query']) | retriever | format_docs
        )
        # 3. Ã‡eviri Promput'unu oluÅŸtur
        | rag_prompt
        # 4. LLM'e gÃ¶nder ve cevabÄ± al
        | llm
        | RunnableLambda(lambda x: x.content)
    )

    # 5. ArayÃ¼z ve Sohbet GeÃ§miÅŸi
    if "messages" not in st.session_state:
        st.session_state.messages = []

    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])

    if prompt := st.chat_input("TÃ¼rkÃ§e veya Ä°ngilizce bir cÃ¼mle girin..."):
        st.session_state.messages.append({"role": "user", "content": prompt})
        with st.chat_message("user"):
            st.markdown(prompt)

        with st.chat_message("assistant"):
            with st.spinner("Ã‡eviri yapÄ±lÄ±yor..."):
                try:
                    # RAG Zincirini Ã‡alÄ±ÅŸtÄ±r
                    response = rag_chain.invoke({"query": prompt})
                except Exception as e:
                    response = f"Ã‡eviri hatasÄ± oluÅŸtu: {e}"
                    st.error(response)
                    
            st.markdown(response)
            st.session_state.messages.append({"role": "assistant", "content": response})

if __name__ == "__main__":
    main()
