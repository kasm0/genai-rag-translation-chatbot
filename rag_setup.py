import os
import kagglehub
# from dotenv import load_dotenv <-- Bu satÄ±rÄ± siliyoruz!
from langchain_google_genai import GoogleGenerativeAIEmbeddings
from langchain_community.vectorstores import Chroma
from langchain_text_splitters import RecursiveCharacterTextSplitter

# ----------------------------------------------------
# 1ï¸âƒ£ Ortam deÄŸiÅŸkenlerini doÄŸrudan OS'tan al (Streamlit Secrets'Ä± kullan)
# ----------------------------------------------------
# load_dotenv() <-- Bu satÄ±r silindi!
GEMINI_API_KEY = os.getenv("GEMINI_API_KEY")

# âš ï¸ UYARI: Streamlit Secrets'ta KAGGLE_USERNAME ve KAGGLE_KEY tanÄ±mlÄ± olmalÄ±dÄ±r.
# kagglehub, bu ortam deÄŸiÅŸkenlerini otomatik olarak kullanÄ±r.

if not GEMINI_API_KEY:
    raise ValueError("âŒ GEMINI_API_KEY bulunamadÄ±. LÃ¼tfen Streamlit Secrets'a ekleyin.")

# ----------------------------------------------------
# 2ï¸âƒ£ Kaggle dataset indir
# ----------------------------------------------------
print("ğŸ“¦ Kaggle dataset indiriliyor...")
dataset_path = kagglehub.dataset_download("seymasa/turkish-to-english-translation-dataset")
print(f"âœ… Dataset baÅŸarÄ±yla indirildi: {dataset_path}")

# ----------------------------------------------------
# 3ï¸âƒ£ TR2EN.txt dosyasÄ±nÄ± oku
# ----------------------------------------------------
print("ğŸ“„ TR2EN.txt dosyasÄ± okunuyor...")

texts = []
file_path = os.path.join(dataset_path, "TR2EN.txt")

if not os.path.exists(file_path):
    raise FileNotFoundError(f"âŒ TR2EN.txt dosyasÄ± {dataset_path} iÃ§inde bulunamadÄ±.")

with open(file_path, "r", encoding="utf-8") as f:
    for line in f:
        parts = line.strip().split("\t")
        if len(parts) == 2:
            eng, tur = parts
            texts.append(f"English: {eng}\nTurkish: {tur}")

print(f"âœ… Toplam {len(texts)} Ã§eviri satÄ±rÄ± iÅŸlendi.")

# âš™ï¸ Test iÃ§in sadece ilk 1000 satÄ±rÄ± kullan (isteÄŸe baÄŸlÄ± hÄ±zlandÄ±rma)
if len(texts) > 1000:
    texts = texts[:1000]
    print("âš ï¸ UyarÄ±: Test iÃ§in sadece ilk 1000 satÄ±r kullanÄ±ldÄ±.")

if len(texts) > 0:
    print("Ä°lk 5 Ã¶rnek:", texts[:5])

# ----------------------------------------------------
# 4ï¸âƒ£ Metinleri parÃ§alara ayÄ±r
# ----------------------------------------------------
print("ğŸ§© Veri parÃ§acÄ±klarÄ± oluÅŸturuluyor...")

splitter = RecursiveCharacterTextSplitter(
    chunk_size=800,
    chunk_overlap=150
)
documents = splitter.create_documents(texts)

print(f"âœ… {len(documents)} metin parÃ§asÄ± oluÅŸturuldu.")

# ----------------------------------------------------
# 5ï¸âƒ£ Embedding + Chroma veritabanÄ±
# ----------------------------------------------------
print("ğŸ’¡ VektÃ¶r veritabanÄ± oluÅŸturuluyor...")

embeddings = GoogleGenerativeAIEmbeddings(
    model="models/text-embedding-004",
    client_options={"api_key": GEMINI_API_KEY}
)

vectorstore = Chroma.from_documents(
    documents=documents,
    embedding=embeddings,
    persist_directory="./chroma_db_translation"
)

print("âœ… VektÃ¶r veritabanÄ± baÅŸarÄ±yla kaydedildi: ./chroma_db_translation")
print("ğŸš€ RAG Setup tamamlandÄ±. ArtÄ±k `app.py` dosyanÄ± Ã§alÄ±ÅŸtÄ±rabilirsin.")
